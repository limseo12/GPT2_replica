Paper Implementation 2 (PI_2)
##현재도 공부중입니다 ㅠ 코드를 전부 이해하려 하는데 오래걸리네요


프로젝트 이름 : GPT2_replica

기간 : 23.05.19 ~ 23.06.12 (총 17일, 주말제외) *GPT에 대하여 공부하기위한 목적이기에 기간이 오래 걸렸습니다.

프로젝트 기획 의도 : 코엑스에서 개최하는 AIEXPO KOREA 2023 국제인공지능대전 (2023.5.10~2023.5.12) 에 방문했을때 모든 기업들이 GPT를 사용한 제품을 발표한 것을 보았습니다.
                    최신 흐름을 따라가야 한다고 생각하여 try 하였습니다.

기능 : 한국어 데이터셋을 학습시켜 한국어로 질의 응답을 할 수 있습니다.

내용 : 

GPT2 :
1. GPT2는 GPT1에서 개선되어 레이어 정규화가 부분 블록의 입력쪽에서 사용되고, 셀프 어텐션 이후에 레이어 정규화 적용
2. GPT2는 GPT1에 비교해 크기가 매우 커진 향상된 모델 사용
3. GPT2- small은 파라미터가 117M (1억1700만)개, Medium은 345M (3억4500만), Large762M (7억6200만), Extra large1542M (15억4200만)

RLHF :

아직도 공부중입니다.
